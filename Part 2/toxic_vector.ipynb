{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71e95756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwesh/scratch/miniconda3/envs/pt/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using GPT-2 (gpt2-large) model with the following configuration:\n",
      "Number of layers (including embeddings): 37\n",
      "Hidden size: 1280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd3bb5e9810>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import from the provided python file\n",
    "from toxic_classification_gpt2 import GPT2Activations, ToxicCommentDataset, HarmfulDetectorMLP\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47c0606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data directory: /home/anwesh/scratch/layers-to-latents/gpt2_activations\n"
     ]
    }
   ],
   "source": [
    "SAVE_DIR = '/home/anwesh/scratch/layers-to-latents/gpt2_activations'\n",
    "RESULTS_CSV = os.path.join(SAVE_DIR, 'results.csv')\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Data directory: {SAVE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb8b8592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Layers by F1 Score:\n",
      "    layer_idx  test_accuracy   test_f1\n",
      "13         13       0.882108  0.890084\n",
      "14         14       0.886913  0.889011\n",
      "11         11       0.884030  0.888786\n",
      "21         21       0.884991  0.888284\n",
      "12         12       0.887074  0.888166\n",
      "\n",
      "Best performing layer is: 13\n"
     ]
    }
   ],
   "source": [
    "# Load the results from the previous training step\n",
    "if os.path.exists(RESULTS_CSV):\n",
    "    results_df = pd.read_csv(RESULTS_CSV)\n",
    "    results_df = results_df.sort_values('test_f1', ascending=False)\n",
    "    print(\"Top 5 Layers by F1 Score:\")\n",
    "    print(results_df.head(5)[['layer_idx', 'test_accuracy', 'test_f1']])\n",
    "    \n",
    "    best_layer_idx = int(results_df.iloc[0]['layer_idx'])\n",
    "    print(f\"\\nBest performing layer is: {best_layer_idx}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Results file not found at {RESULTS_CSV}. Please run the training step first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f19a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['layer_idx', 'train_f1', 'train_accuracy', 'train_tpr', 'train_fpr',\n",
      "       'test_f1', 'test_accuracy', 'test_tpr', 'test_fpr'],\n",
      "      dtype='object')\n",
      "   layer_idx  train_f1  train_accuracy  train_tpr  train_fpr   test_f1  \\\n",
      "0          0  0.903654        0.903482    0.90527   0.098305  0.869914   \n",
      "\n",
      "   test_accuracy  test_tpr  test_fpr  \n",
      "0       0.864809  0.904053  0.174435  \n"
     ]
    }
   ],
   "source": [
    "# Inspect columns\n",
    "if os.path.exists(RESULTS_CSV):\n",
    "    df = pd.read_csv(RESULTS_CSV)\n",
    "    print(df.columns)\n",
    "    print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f9d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HarmfulVectorConstructor:\n",
    "    def __init__(self, activation_dir):\n",
    "        self.activation_dir = activation_dir\n",
    "\n",
    "    def get_mean_difference_vector(self, layer_idx):\n",
    "        \"\"\"Construct vector by subtracting mean of non-toxic from toxic activations.\"\"\"\n",
    "        data = np.load(os.path.join(self.activation_dir, f'train_layer_{layer_idx}_pooled_activations.npy'))\n",
    "        labels = np.load(os.path.join(self.activation_dir, 'train_labels.npy'))\n",
    "        \n",
    "        toxic_mean = np.mean(data[labels==1], axis=0)\n",
    "        non_toxic_mean = np.mean(data[labels==0], axis=0)\n",
    "        vector = toxic_mean - non_toxic_mean\n",
    "        return vector / np.linalg.norm(vector)\n",
    "\n",
    "    def get_logistic_vector(self, layer_idx):\n",
    "        \"\"\"Construct vector using the weights of a Logistic Regression classifier.\"\"\"\n",
    "        data = np.load(os.path.join(self.activation_dir, f'train_layer_{layer_idx}_pooled_activations.npy'))\n",
    "        labels = np.load(os.path.join(self.activation_dir, 'train_labels.npy'))\n",
    "        \n",
    "        # Train a simple linear probe\n",
    "        clf = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
    "        clf.fit(data, labels)\n",
    "        \n",
    "        # The coefficient vector points in the direction of the positive class (toxic)\n",
    "        vector = clf.coef_[0]\n",
    "        return vector / np.linalg.norm(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "114675c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafetyHookManager:\n",
    "    \"\"\"Manages forward hooks to remove harmful components during inference\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.hooks = []\n",
    "        self.device = device\n",
    "    \n",
    "    def register_hooks(self, layer_vectors, alpha):\n",
    "        \"\"\"\n",
    "        Register hooks for specified layers.\n",
    "        layer_vectors: dict {layer_idx: vector_numpy}\n",
    "        alpha: float scaling factor\n",
    "        \"\"\"\n",
    "        self.clear_hooks()\n",
    "        \n",
    "        for layer_idx, vector in layer_vectors.items():\n",
    "            # Convert to tensor\n",
    "            v = torch.tensor(vector, dtype=torch.float32, device=self.device)\n",
    "            \n",
    "            # Create the hook function for this specific vector and alpha\n",
    "            hook_fn = self._get_hook_fn(v, alpha)\n",
    "            \n",
    "            # Register hook to the specific transformer block\n",
    "            # GPT2 structure: model.h is the ModuleList of blocks\n",
    "            if 0 <= layer_idx < len(self.model.h):\n",
    "                module = self.model.h[layer_idx]\n",
    "                self.hooks.append(module.register_forward_hook(hook_fn))\n",
    "            else:\n",
    "                print(f\"Warning: Layer {layer_idx} out of bounds\")\n",
    "                \n",
    "    def _get_hook_fn(self, harmful_vector, alpha):\n",
    "        \"\"\"Create the actual hook function\"\"\"\n",
    "        def hook(module, input, output):\n",
    "            # GPT2Block returns tuple (hidden_states, present_key_values, ...)\n",
    "            if isinstance(output, tuple):\n",
    "                hidden_states = output[0]\n",
    "            else:\n",
    "                hidden_states = output\n",
    "                \n",
    "            # Ensure vector is on correct device/dtype\n",
    "            v = harmful_vector.to(hidden_states.device).to(hidden_states.dtype)\n",
    "            \n",
    "            # Project: (batch, seq, dim) . (dim) -> (batch, seq)\n",
    "            # Calculate projection of hidden states onto harmful vector\n",
    "            # We assume v is normalized\n",
    "            projections = torch.matmul(hidden_states, v)\n",
    "            \n",
    "            # Subtract: h' = h - alpha * (h . v) * v\n",
    "            # We unsqueeze projection to (batch, seq, 1) to broadcast\n",
    "            modified_hidden = hidden_states - alpha * projections.unsqueeze(-1) * v\n",
    "            \n",
    "            # Return modified output in original format\n",
    "            if isinstance(output, tuple):\n",
    "                return (modified_hidden,) + output[1:]\n",
    "            else:\n",
    "                return modified_hidden\n",
    "        return hook\n",
    "\n",
    "    def clear_hooks(self):\n",
    "        \"\"\"Remove all registered hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_safety(gpt2_extractor, test_loader, hook_manager, layer_vectors, alpha, judge_mlp, judge_layer_idx):\n",
    "    \"\"\"\n",
    "    Run inference with hooks and evaluate using the Judge MLP.\n",
    "    \"\"\"\n",
    "    # Register hooks\n",
    "    if alpha > 0:\n",
    "        hook_manager.register_hooks(layer_vectors, alpha)\n",
    "    else:\n",
    "        hook_manager.clear_hooks()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    gpt2_extractor.model.eval()\n",
    "    judge_mlp.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Eval alpha={alpha}\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(gpt2_extractor.device)\n",
    "            attention_mask = batch['attention_mask'].to(gpt2_extractor.device)\n",
    "            labels = batch['label'].numpy()\n",
    "            \n",
    "            # Run model with hooks\n",
    "            # We need hidden states to feed into the Judge MLP\n",
    "            outputs = gpt2_extractor.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=True\n",
    "            )\n",
    "            \n",
    "            # Extract activations from the Judge Layer\n",
    "            # hidden_states[0] = embeddings\n",
    "            # hidden_states[i] = output of layer i-1\n",
    "            # So output of layer K is at index K+1\n",
    "            judge_activations = outputs.hidden_states[judge_layer_idx + 1]\n",
    "            \n",
    "            # Mean Pooling (consistent with training)\n",
    "            # Mask: (batch, seq, 1)\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(judge_activations.size()).float()\n",
    "            sum_embeddings = torch.sum(judge_activations * mask_expanded, 1)\n",
    "            sum_mask = mask_expanded.sum(1)\n",
    "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "            pooled_activations = sum_embeddings / sum_mask\n",
    "            \n",
    "            # Judge Classification\n",
    "            mlp_out = judge_mlp(pooled_activations)\n",
    "            preds = (mlp_out > 0.5).cpu().numpy().flatten()\n",
    "            \n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "            \n",
    "    # Cleanup\n",
    "    hook_manager.clear_hooks()\n",
    "    \n",
    "    # Metrics\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    return f1, acc, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9a853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GPT-2 and DataLoader...\n",
      "Now using GPT-2 (gpt2-large) model with the following configuration:\n",
      "Number of layers (including embeddings): 37\n",
      "Hidden size: 1280\n",
      "Now using GPT-2 (gpt2-large) model with the following configuration:\n",
      "Number of layers (including embeddings): 37\n",
      "Hidden size: 1280\n",
      "Loading Judge MLP for Layer 13...\n",
      "\n",
      "Starting Safety Alignment Experiments...\n",
      "================================================================================\n",
      "\n",
      "Method: MEAN_DIFF\n",
      "  Editing Top 1 Layers: [13]\n",
      "Loading Judge MLP for Layer 13...\n",
      "\n",
      "Starting Safety Alignment Experiments...\n",
      "================================================================================\n",
      "\n",
      "Method: MEAN_DIFF\n",
      "  Editing Top 1 Layers: [13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Alpha 0.0: F1=0.8885, Acc=0.8798, FPR=0.1985, TPR=0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Alpha 0.5: F1=0.4339, Acc=0.5270, FPR=0.3085, TPR=0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Alpha 1.0: F1=0.3223, Acc=0.4477, FPR=0.3673, TPR=0.2627\n",
      "  Editing Top 3 Layers: [13 14 11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval alpha=0.0:  48%|████▊     | 186/391 [03:11<03:30,  1.03s/it]"
     ]
    }
   ],
   "source": [
    "# 1. Initialize Model and Data\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"Initializing GPT-2 and DataLoader...\")\n",
    "# Reduce batch size to avoid OOM\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "gpt2_extractor = GPT2Activations() # Loads model\n",
    "test_dataset = ToxicCommentDataset(split='test', tokenizer=gpt2_extractor.tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 2. Load Judge MLP (Best Layer)\n",
    "print(f\"Loading Judge MLP for Layer {best_layer_idx}...\")\n",
    "judge_mlp = HarmfulDetectorMLP(input_size=gpt2_extractor.h_size).to(DEVICE)\n",
    "judge_mlp.load_state_dict(torch.load(os.path.join(SAVE_DIR, f'mlp_layer_{best_layer_idx}_model.pth')))\n",
    "\n",
    "# 3. Experiment Setup\n",
    "alphas = [0.0, 0.5, 1.0]\n",
    "layer_counts = [1, 3, 5, 10]\n",
    "methods = ['mean_diff', 'logistic']\n",
    "\n",
    "results = []\n",
    "constructor = HarmfulVectorConstructor(SAVE_DIR)\n",
    "hook_manager = SafetyHookManager(gpt2_extractor.model, DEVICE)\n",
    "\n",
    "# 4. Run Experiments\n",
    "print(\"\\nStarting Safety Alignment Experiments...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nMethod: {method.upper()}\")\n",
    "    \n",
    "    for n_layers in layer_counts:\n",
    "        # Get top N layers\n",
    "        top_layers = results_df.head(n_layers)['layer_idx'].values.astype(int)\n",
    "        print(f\"  Editing Top {n_layers} Layers: {top_layers}\")\n",
    "        \n",
    "        # Construct vectors\n",
    "        layer_vectors = {}\n",
    "        for layer_idx in top_layers:\n",
    "            if method == 'mean_diff':\n",
    "                vec = constructor.get_mean_difference_vector(layer_idx)\n",
    "            else:\n",
    "                vec = constructor.get_logistic_vector(layer_idx)\n",
    "            layer_vectors[layer_idx] = vec\n",
    "            \n",
    "        # Evaluate alphas\n",
    "        for alpha in alphas:\n",
    "            # Clear cache before each evaluation run\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            f1, acc, fpr, tpr = evaluate_safety(\n",
    "                gpt2_extractor, test_loader, hook_manager, \n",
    "                layer_vectors, alpha, judge_mlp, best_layer_idx\n",
    "            )\n",
    "            \n",
    "            print(f\"    Alpha {alpha}: F1={f1:.4f}, Acc={acc:.4f}, FPR={fpr:.4f}, TPR={tpr:.4f}\")\n",
    "            \n",
    "            results.append({\n",
    "                'method': method,\n",
    "                'n_layers': n_layers,\n",
    "                'alpha': alpha,\n",
    "                'f1': f1,\n",
    "                'acc': acc,\n",
    "                'fpr': fpr,\n",
    "                'tpr': tpr\n",
    "            })\n",
    "\n",
    "# 5. Display and Save Results\n",
    "final_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(final_df)\n",
    "\n",
    "# Save\n",
    "final_df.to_csv(os.path.join(SAVE_DIR, 'safety_alignment_results.csv'), index=False)\n",
    "print(f\"\\nResults saved to {os.path.join(SAVE_DIR, 'safety_alignment_results.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25229298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
